### Hello, I'm Federico üëã

I am currently working as a Data Scientist at the [Energy and Environment Lab](https://urbanlabs.uchicago.edu/labs/energy-environment) at the University of Chicago. I previously worked at:

- [deep_dive](https://dive.ai/) as a Senior Data Scientist.
- [Coding it Forward](https://codingitforward.com/) as a Data Engineering Fellow for the City of Long Beach, CA.
- [UChicago Justice Project](https://justiceproject.uchicago.edu/) as a Data Science Research Assistant.

I obtained my MS in Computational Analysis and Public Policy at the University of Chicago, where I delved deep into Machine Learning, Natural Language Processing, and Cloud Computing. I have worked on a wide variety of projects, including webscraping, supervised and unsupervised ML models, data visualization, and process automation. I have also designed the underlying AWS architecture in most of the projects I have worked on. 

Feel free to take a look at my [resume](https://github.com/FedericoDM/federicodm.github.io/blob/main/public/Resume_FedericoDominguezMolina.pdf), check my [website](https://federicodm.github.io/), or connect with me via [LinkedIn](https://www.linkedin.com/in/federico-dominguez-molina/).

- üêç: The programming languages I use are Python, SQL, C, and R.
- ‚òÅÔ∏è: Cloud Computing Stack: AWS (EC2, Lambda, SQS, Neptune, DynamoDB, Firehose, Glue, EventBridge, Route53).
- üìä: Other skills: Power BI, Databricks, and Elasticsearch.
- üìñ Currently working on: Natural Language Processing, AWS, and Network Analysis.

Some of the projects that I have worked on, among others, are:

- Design webscraping pipelines to visualize goods' prices over time.
- Supervised Machine Learning to predict price changes over time.
- Unsupervised Machine Learning to create recommender systems.
- Real-time media alerts.

You can see some of my work on the following repositories:

1) ü§ñ  **Twitter user extraction and classification with Python from different cities around the world**: While at the UChicago Energy and Environment Lab, I have been working on automatically extracting, classifying, and building networks for Twitter users from around 50+ cities around the world. The users are classified based on their tweets and their biography using an LLM approach, and we use AWS Neptune to store and analyze each city's network to find its most influential users (_Repository is currently private until further notice_).
2) üå≤ [Streamlit App to extract CO2 emissions data in real time](https://github.com/City-of-Long-Beach-Public/climate_inventory): I worked with the City of Long Beach (CA) to automate their data extraction process from public websites. As a result, I created a Streamlit app that allows them to select the website they want and the year of interest. They can also download the data into their local computer.    
3) üí∞ [Weekly alert system to manage household expenses via Splitwise's API](https://github.com/FedericoDM/splitwise-household-expenses): In order to better manage our household's budget and expenses, I created a pipeline that extracts our expenses data from the Splitwise API. Then, every week, we get an email that summarizes our expenses for the current month.
4) üí¨ [Natural Language Processing Analysis of the previous Mexican President's Daily Conferences](https://github.com/FedericoDM/AMLO-NLP): As part of a class project (and also personal interest), I scraped all of the president's morning conferences and trained a model to assign each conference an 'aggressivity score', based on how hostile he is in the press conference. 
5) üó∫Ô∏è [API extraction codes I have used in other projects](https://github.com/FedericoDM/API-extractions): You can mostly find some code samples of API extractions I have done in the past for different projects. These range from Financial to Government APIs.  
6) üìä [Some webscraping side projects I have previously worked on](https://github.com/FedericoDM/webscraping-sideprojects): Here, you can find some code I created to extract data from different websites, per different clients' request. In these cases, the main goal was to get and deliver the clean data to the final user.

<!--
![FedericoDM's GitHub stats](https://github-readme-stats-sigma-five.vercel.app/api?username=FedericoDM&show_icons=true&theme=codeSTACKr&count_private=true)
-->

[![GitHub Streak](http://github-readme-streak-stats.herokuapp.com?user=FedericoDM&theme=dark&background=000000)](https://git.io/streak-stats)


<!--
[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=FedericoDM&layout=compact&theme=vision-friendly-dark)](https://github.com/anuraghazra/github-readme-stats)
-->

<!--
**FedericoDM/FedericoDM** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
-->
